# ML-Xgboost
This is one of the task for "Introduction to Machine Learning" course in CS Department at NCCU. The objective of this task is a six-class classification problem.  

I experimented with multiple models, including **Random Forest**, **KNN**, and others, and also attempted to leverage a **VotingClassifier** to combine the strengths of different models. Ultimately, **XGBoost** delivered the best predictive performance. To further optimize it, I used **GridSearchCV** to fine-tune the hyperparameters. As a result, I placed **6th out of 39 students in this challenge.**
